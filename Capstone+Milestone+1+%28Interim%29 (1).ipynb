{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eacfaaf7",
   "metadata": {},
   "source": [
    "***Deep Learning based Car Identification***\n",
    "\n",
    "- Automotive, Surveillance, Object Detection & Localisation\n",
    "\n",
    "*Project By:*\n",
    "1. Kaushik Sharma\n",
    "2. Himanshu Singal\n",
    "3. Sunil Dutta\n",
    "4. Priyamvada Saxena \n",
    "5. Bharat Singh\n",
    "\n",
    "*Project For:\n",
    "Captstone project for Post Graduate Program in Artificial Intelligence and Machine Learning\n",
    "with GreatLakes & Texas McCombs School of Business, The University of Texas at Austin*\n",
    "\n",
    "CONTEXT:\n",
    "Computer vision can be used to automate supervision and generate action appropriate action trigger if the event is predicted from the image of interest. For example a car moving on the road can be easily identi ied by a camera as make of the car, type, colour, number plates etc.\n",
    "\n",
    "DATA DESCRIPTION:\n",
    "The Cars dataset contains 16,185 images of 196 classes of cars. The data is split into 8,144 training images and 8,041 testing images, where each class has been split roughly in a 50-50 split. Classes are typically at the level of Make, Model, Year, e.g. 2012 Tesla Model S or 2012 BMW M3 coupe.\n",
    "\n",
    "‣ *Train Images:* Consists of real images of cars as per the make and year of the car.\n",
    "\n",
    "‣ *Test Images:* Consists of real images of cars as per the make and year of the car.\n",
    "\n",
    "‣ *Train Annotation:* Consists of bounding box region for training images.\n",
    "\n",
    "‣ *Test Annotation:* Consists of bounding box region for testing images.\n",
    "\n",
    "MILESTONE 1:\n",
    "\n",
    "‣ Step 1: Import the data\n",
    "\n",
    "‣ Step 2: Map training and testing images to its classes.\n",
    "\n",
    "‣ Step 3: Map training and testing images to its annotations.\n",
    "\n",
    "‣ Step 4: Display images with bounding box\n",
    "\n",
    "‣ Step 5: Design, train and test basic CNN models to classify the car. \n",
    "\n",
    "‣ Step 6: Interim report "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c9f17e",
   "metadata": {},
   "source": [
    "Step 1: Import the data\n",
    "\n",
    "The following libraries and packages are used for reading the csv files, processing the data and visualizing the data / images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fc8ddb0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9620/3673720139.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbitwise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mv1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mforward_compatibility_horizon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbitwise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\compat\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mv1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mforward_compatibility_horizon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mforward_compatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\compat\\v2\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__internal__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__operators__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maudio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v2\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbitwise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v2\\compat\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mv1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mforward_compatibility_horizon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mforward_compatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v2\\compat\\v2\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[0m_current_module\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msummary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m   _current_module.__path__ = (\n\u001b[0;32m    331\u001b[0m       [_module_util.get_parent_dir(summary)] + _current_module.__path__)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorboard\\summary\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# If the V1 summary API is accessible, load and re-export it here.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mv1\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorboard\\summary\\v1.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudio\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msummary\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_audio_summary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcustom_scalar\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msummary\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_custom_scalar_summary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistogram\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msummary\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_histogram_summary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msummary\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_image_summary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpr_curve\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msummary\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_pr_curve_summary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorboard\\plugins\\histogram\\summary.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistogram\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistogram\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msummary_v2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorboard\\plugins\\histogram\\summary_v2.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistogram\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlazy_tensor_creator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorboard\\util\\tensor_util.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensor_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensorflow_stub\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeta_graph_pb2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary_pb2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mas_dtype\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDType\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstring\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtypes_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgfile\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mbotocore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[1;32mimport\u001b[0m \u001b[0mboto3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mS3_ENABLED\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\boto3\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mboto3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_warn_deprecated_python\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mboto3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSession\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0m__author__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Amazon Web Services'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\boto3\\session.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mbotocore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbotocore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbotocore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataNotFoundError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUnknownServiceError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\botocore\\session.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mbotocore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbotocore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfigloader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbotocore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\botocore\\client.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mbotocore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxform_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbotocore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mClientArgsCreator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbotocore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauth\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAUTH_TYPE_MAPS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\botocore\\waiter.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjmespath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mbotocore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdocstring\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWaiterDocstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbotocore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_service_module_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\botocore\\docs\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mbotocore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mservice\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mServiceDocumenter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\botocore\\docs\\service.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# language governing permissions and limitations under the License.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbotocore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbcdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestdoc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDocumentStructure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mbotocore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mClientDocumenter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mClientExceptionsDocumenter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbotocore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpaginator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPaginatorDocumenter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbotocore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaiter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWaiterDocumenter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\botocore\\docs\\client.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# language governing permissions and limitations under the License.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbotocore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mbotocore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexample\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mResponseExampleDocumenter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m from botocore.docs.method import (\n\u001b[0;32m     16\u001b[0m     \u001b[0mdocument_custom_method\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\botocore\\docs\\example.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# ANY KIND, either express or implied. See the License for the specific\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# language governing permissions and limitations under the License.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mbotocore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mShapeDocumenter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbotocore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpy_default\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\botocore\\docs\\shape.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# inherited from a Documenter class with the appropriate methods\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# and attributes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mbotocore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mis_json_value_header\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\botocore\\utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbotocore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbotocore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mawsrequest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mbotocore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhttpsession\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;31m# IP Regexes retained for backwards compatibility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\botocore\\httpsession.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;31m# Always import the original SSLContext, even if it has been patched\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0murllib3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyopenssl\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0morig_util_SSLContext\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mSSLContext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0murllib3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mssl_\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSSLContext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\contrib\\pyopenssl.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcryptography\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mx509\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcryptography\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhazmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopenssl\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopenssl_backend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcryptography\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhazmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopenssl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx509\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_Certificate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\cryptography\\hazmat\\backends\\openssl\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcryptography\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhazmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopenssl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\cryptography\\hazmat\\backends\\openssl\\backend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mXTS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m )\n\u001b[1;32m--> 150\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcryptography\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhazmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimitives\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkdf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscrypt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcryptography\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhazmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimitives\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserialization\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpkcs7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mssh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcryptography\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx509\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mocsp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mpath_stats\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import necessary libraries for Milestone 1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import re, cv2\n",
    "\n",
    "from PIL import Image\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef862ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from plotly import express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238a4a0a",
   "metadata": {},
   "source": [
    "**Read CSV** : Read the car names and make and change the name of the column to \"fullNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe32c412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the car/class names\n",
    "carsMaster = pd.read_csv(\"Car names and make.csv\",header=None)\n",
    "carsMaster.columns=[\"fullNames\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2183655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display sample data\n",
    "carsMaster.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df6def4",
   "metadata": {},
   "source": [
    "**Read Word Count :**\n",
    "\n",
    "By understanding the length of the words, we can plan to split the OEM, Model, Type and Year part from the fullName\n",
    "\n",
    "The following help us to understand that most of the entries are of 4 words and around 6 of them are having word length as 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b0c525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets review the name lengths\n",
    "carsMaster[\"wCounts\"] = carsMaster[\"fullNames\"].apply(lambda x: len(x.split()))\n",
    "carsMaster.wCounts.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bf072f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets review the 7 word long names\n",
    "print(carsMaster.loc[carsMaster.wCounts==7,[\"fullNames\"]].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794665a8",
   "metadata": {},
   "source": [
    "**Cleanup Process**\n",
    "\n",
    "Remove '/' character from the entries for further spliting them to OEM, Model, Type and Year values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14808935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before we process any information from the fullNames, lets remove any path separator '/' in the class names\n",
    "carsMaster[\"fullNames\"] = carsMaster[\"fullNames\"].apply(lambda x: '-'.join(x.split('/')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bafa308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first separate the OEM name & Year-of-Make data and review again\n",
    "carsMaster[\"OEM\"] = carsMaster[\"fullNames\"].apply(lambda x: x.split()[0])\n",
    "carsMaster[\"YEAR\"] = carsMaster[\"fullNames\"].apply(lambda x: x.split()[-1])\n",
    "\n",
    "# also pickup the second word to verify if it was part of OEM name or Model name\n",
    "carsMaster[\"chk\"] = carsMaster[\"fullNames\"].apply(lambda x: x.split()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a53013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display sample data\n",
    "carsMaster.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7ecaa3",
   "metadata": {},
   "source": [
    "**Analysis of string data**\n",
    "\n",
    "This will help us to understand the combinations of OEM column value with the multiple values in chk column. This will help to develop a logic based on the pattern in which the OEM and Model names are placed in the entry names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23947c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets review on basis of OEM\n",
    "dtmp = carsMaster.groupby(by=\"OEM\")[\"chk\"].unique()\n",
    "dtmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a5068d",
   "metadata": {},
   "source": [
    "**Analysis of the string data after the first word**\n",
    "\n",
    "Get only the entries where the entry in chk is 1 list item or unique item.\n",
    "\n",
    "eg; AM has only one unique value in chk column ie; [General]\n",
    "\n",
    "whereas Acura has multiple words in chk column [RL, TL, TSX, Integra, ZDX].\n",
    "\n",
    "This will help to conclude that any entries with only 1 value in 'chk' column is part of OEM name and not Model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeead916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the suspects for 2 word OEM names are whereever there are only 1 uniques against the extracted first name of the OE\n",
    "# lets try to short list those and review better\n",
    "carsMaster.loc[carsMaster.OEM.isin(dtmp.loc[carsMaster.groupby(by=\"OEM\")[\"chk\"].nunique()==1].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c62b741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets review the model names and extract model type information from it\n",
    "carsMaster[\"MODEL\"] = carsMaster[\"fullNames\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccde221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# review model name lenghts\n",
    "carsMaster.wCounts.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2be0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display few significant model names based on word counts\n",
    "carsMaster.loc[carsMaster.wCounts==5,\"MODEL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc9c503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the values from dataframe for word count ==4\n",
    "\n",
    "carsMaster.loc[carsMaster['wCounts']==4,\"OEM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b42e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the values from datafrane for word count ==3\n",
    "\n",
    "carsMaster.loc[carsMaster.wCounts==3,\"OEM\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae02d51",
   "metadata": {},
   "source": [
    "**Pattern to extract the Model and Type**\n",
    "\n",
    "Note that Cab & Van comes with 2 word coach type. Otherwise, almost every other words are part of model name only. Hence we can separate the coach type\n",
    "\n",
    "Extract the type value to a new column \"Type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4700f7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the TYPE info\n",
    "carsMaster['TYPE'] = carsMaster.MODEL.apply(lambda x: x[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885ed70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique values in Type column\n",
    "\n",
    "# review\n",
    "carsMaster.TYPE.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c651fc",
   "metadata": {},
   "source": [
    "**Findings**\n",
    "\n",
    "The type IPL hides Coupe type before it\n",
    "\n",
    "'Type-S', 'R', 'GS', 'ZR1', 'Z06', 'Abarth', 'XKR' types are not coach types, hence to be markes as unKnown\n",
    "\n",
    "'SS', 'SRT-8', 'SRT8' could be considered as car type (though not coach type) as they are technology/class of car\n",
    "\n",
    "We can update the TYPE accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f6a681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets update the TYPE\n",
    "for t in ['Type-S', 'R', 'GS',  'ZR1', 'Z06', 'Abarth', 'XKR']:\n",
    "    carsMaster.loc[carsMaster.TYPE == t,\"TYPE\"] = 'UnKnown'\n",
    "carsMaster.loc[carsMaster.TYPE == 'IPL',\"TYPE\"] = \"Coupe\"\n",
    "carsMaster.loc[carsMaster.TYPE == 'Cab',\"TYPE\"] = carsMaster.loc[carsMaster.TYPE == 'Cab',\"MODEL\"].apply(lambda x: x[-2:])\n",
    "carsMaster.loc[carsMaster.TYPE == 'Van',\"TYPE\"] = carsMaster.loc[carsMaster.TYPE == 'Van',\"MODEL\"].apply(lambda x: x[-2:])\n",
    "carsMaster.loc[carsMaster.TYPE == 'SRT-8',\"TYPE\"] = \"SRT8\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84892234",
   "metadata": {},
   "source": [
    "**Update Model names for all entries, excluding the Type information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a0203d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets update the MODEL name excluding the TYPE information\n",
    "carsMaster[\"MODEL\"] = carsMaster.apply(lambda row: [w for w in row[\"fullNames\"].split() if w not in row[\"OEM\"] and w!=str(row[\"YEAR\"]) and w not in row[\"TYPE\"]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd6d9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display sample\n",
    "display(carsMaster.sample(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d303f920",
   "metadata": {},
   "source": [
    "Combine the OEM names, Model Names and Type\n",
    "\n",
    "Combine the values using \"_\" if the values in Model name or Type is a list else, display as such"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1cd5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets properly combine the OEM names & Model Names without lists\n",
    "carsMaster[\"OEM\"] = carsMaster[\"OEM\"].apply(lambda x: x if type(x)==str else '_'.join(x))\n",
    "carsMaster[\"MODEL\"] = carsMaster[\"MODEL\"].apply(lambda x: x if type(x)==str else '_'.join(x))\n",
    "carsMaster[\"TYPE\"] = carsMaster[\"TYPE\"].apply(lambda x: x if type(x)==str else '_'.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ef3d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display sample\n",
    "display(carsMaster.sample(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab56cbf",
   "metadata": {},
   "source": [
    "**Finalize the schema / structure of Master Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcff5a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets drop & rearrange the master data\n",
    "carsMaster = carsMaster[[\"fullNames\",\"OEM\",\"MODEL\",\"TYPE\",\"YEAR\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da03b7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display samples\n",
    "carsMaster.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249f8963",
   "metadata": {},
   "source": [
    "**Print Summary Information**\n",
    "\n",
    "Print unique values count of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98118dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# review number of unique classes\n",
    "print(\"Number of unique classes:\")\n",
    "print(\"OEMs :\",carsMaster.OEM.nunique())\n",
    "print(\"MODELs :\",carsMaster.MODEL.nunique())\n",
    "print(\"TYPEs :\",carsMaster.TYPE.nunique())\n",
    "print(\"YEARs :\",carsMaster.YEAR.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71413ab",
   "metadata": {},
   "source": [
    "**Visualization** - Data Distribution\n",
    "\n",
    "**BAR CHART**\n",
    "\n",
    "A bar chart is used to show the distribution of data points so that we can perform a comparison of metric values across different subgroups. From the chart, we can see which groups are highest or most common, and how other group compare against the others.\n",
    "\n",
    "Number of Models available under each OEM value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863129ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of models from each OEM\n",
    "plt.figure(figsize = (25,5))\n",
    "ax = sns.barplot(x=carsMaster[\"OEM\"].value_counts().index,y=carsMaster[\"OEM\"].value_counts().values) # display bars\n",
    "ax.bar_label(ax.containers[0]) # display counts\n",
    "plt.title(\"Number of models from each OEM\",x=0.5,y=0.9)\n",
    "plt.ylabel(\"number of models\")\n",
    "plt.xticks(rotation=60);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66052de",
   "metadata": {},
   "source": [
    "**Distribution** : Total number of OEMs - 49\n",
    "\n",
    "The Chevrolet is having 11% of contribution for the various models\n",
    "\n",
    "The Ram, Porsche, AM General, Jaguar, smart are few models that are contributing only 0.05% of the models\n",
    "\n",
    "This help to understand about the imbalance of data for OEM and Models in the dataset\n",
    "\n",
    "**Number of Types available under each Model value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d00b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of models from each TYPE of coach\n",
    "plt.figure(figsize = (25,5))\n",
    "ax = sns.barplot(x=carsMaster[\"TYPE\"].value_counts().index,y=carsMaster[\"TYPE\"].value_counts().values) # display bars\n",
    "ax.bar_label(ax.containers[0]) # display counts\n",
    "plt.title(\"Number of models from each TYPE\",x=0.5,y=0.9)\n",
    "plt.ylabel(\"number of models\")\n",
    "plt.xticks(rotation=60);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4448fc",
   "metadata": {},
   "source": [
    "**Distribution** : Total number of Sedan - 46\n",
    "\n",
    "The Mitsubishi-Sedan is having 23% of contribution for the various models-types\n",
    "\n",
    "The Club Cab, Wagon Van, Passenger Van are few models types that are contributing only 0.05% of the model-types\n",
    "\n",
    "This help to understand about the imbalance of data for Model and Types in the dataset\n",
    "\n",
    "**Number of Models available under each Year**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84945d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of models from each YEAR\n",
    "plt.figure(figsize = (25,5))\n",
    "ax = sns.barplot(x=carsMaster[\"YEAR\"].value_counts().index,y=carsMaster[\"YEAR\"].value_counts().values) # display bars\n",
    "ax.bar_label(ax.containers[0]) # display counts\n",
    "plt.title(\"Number of models from each YEAR\",x=0.5,y=0.9)\n",
    "plt.ylabel(\"number of models\")\n",
    "plt.xticks(rotation=60);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789e6d0e",
   "metadata": {},
   "source": [
    "**Distribution** : Total number of Models in the year 2012 - 117\n",
    "\n",
    "The 2012 is having 60% of contribution for the various models for the years\n",
    "\n",
    "The models from 1991-2000 is having the least contribution of models counting to 0.05%\n",
    "\n",
    "This help to understand about the imbalance of data for Models and Year in the dataset\n",
    "\n",
    "**Observations from the Visualization - Bias**\n",
    "\n",
    "There are imbalances in the dataset might create bias in the model's capabilities\n",
    "\n",
    "**Bias Type** : Data Collection Bias\n",
    "\n",
    "**Description** : Bias introduced by the selection of individuals, groups (eg; OEM, Model, Type, Year) in such a way that proper randomization is not achieved. This will fail to ensure that the sample obtained is representative of the population intended to be analyzed.\n",
    "\n",
    "We could clearly understand that the contribution by few OEM , few Models and selected years are more than others. This will lead to the model being biased towards some OEM-Model-Year cars.\n",
    "\n",
    "Eg; the model learns more of \"Chevrolet\" OEM than others. will learn \"Sedan\" Model than others and 2012 Year Model than others\n",
    "\n",
    "To reconfirm the findings, let us also read the image data files in to our notebook, and review the distribution once again\n",
    "\n",
    "**Step 2:** Map training and testing images to its classes.\n",
    "\n",
    "Read Images for test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f06e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import zipfile\n",
    "\n",
    "!unzip archive.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a673bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference paths\n",
    "BASEfldr = 'car_data/car_data'\n",
    "TRAINfldr = 'train/'\n",
    "TESTfldr = 'test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e2ede2",
   "metadata": {},
   "source": [
    "**Train images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c1da7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets take a record of data about the training imagess\n",
    "tfi = tf.keras.preprocessing.image\n",
    "path = os.path.join(BASEfldr,TRAINfldr)\n",
    "iCols = [\"Image\",\"ImagePath\",\"folderName\"]\n",
    "imageMasterTrain = pd.DataFrame(columns=iCols)\n",
    "imPath = np.empty(0)\n",
    "fldrName = np.empty(0)\n",
    "imageName = np.empty(0)\n",
    "imH = np.empty(0)\n",
    "imW = np.empty(0)\n",
    "for cls in tqdm(carsMaster.fullNames,desc=\"imScanTrain\"):\n",
    "    # we can also do this with if os.isdir() check\n",
    "    try:\n",
    "        os.listdir(path+cls)\n",
    "    except:\n",
    "        print(\"path error: \",path+cls)\n",
    "        continue\n",
    "    for img in os.listdir(path+cls):\n",
    "        imPath = np.append(imPath,np.array([path+cls+'/'+img]))\n",
    "        fldrName = np.append(fldrName,np.array([cls]))\n",
    "        imageName = np.append(imageName,np.array([img]))\n",
    "        (w,h) = tfi.load_img(path+cls+'/'+img).size\n",
    "        imH = np.append(imH,np.array([h]))\n",
    "        imW = np.append(imW,np.array([w])) \n",
    "        \n",
    "imageMasterTrain[\"Image\"] = imageName\n",
    "imageMasterTrain[\"ImagePath\"] = imPath\n",
    "imageMasterTrain[\"folderName\"] = fldrName\n",
    "imageMasterTrain[\"height\"] = imH\n",
    "imageMasterTrain[\"width\"] = imW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8071b4e",
   "metadata": {},
   "source": [
    "**Test images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c242bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets take a record of data about the testing imagess\n",
    "path= os.path.join(BASEfldr,TESTfldr)\n",
    "iCols = [\"Image\",\"ImagePath\",\"folderName\"]\n",
    "imageMasterTest = pd.DataFrame(columns=iCols)\n",
    "imPath = np.empty(0)\n",
    "fldrName = np.empty(0)\n",
    "imageName = np.empty(0)\n",
    "imH = np.empty(0)\n",
    "imW = np.empty(0)\n",
    "for cls in tqdm(carsMaster.fullNames,desc=\"imScanTest\"):\n",
    "    # we can also do this with if os.isdir() check\n",
    "    try:\n",
    "        os.listdir(path+cls)\n",
    "    except:\n",
    "        print(\"path error: \",cls)\n",
    "        continue\n",
    "    for img in os.listdir(path+cls):\n",
    "        imPath = np.append(imPath,np.array([path+cls+'/'+img]))\n",
    "        fldrName = np.append(fldrName,np.array([cls]))\n",
    "        imageName = np.append(imageName,np.array([img]))\n",
    "        (w,h) = tfi.load_img(path+cls+'/'+img).size\n",
    "        imH = np.append(imH,np.array([h]))\n",
    "        imW = np.append(imW,np.array([w])) \n",
    "imageMasterTest[\"Image\"] = imageName\n",
    "imageMasterTest[\"ImagePath\"] = imPath\n",
    "imageMasterTest[\"folderName\"] = fldrName\n",
    "imageMasterTest[\"height\"] = imH\n",
    "imageMasterTest[\"width\"] = imW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d8be28",
   "metadata": {},
   "source": [
    "**Compute image size**\n",
    "\n",
    "Store the image size details like height, width and pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471964fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update training image sizes\n",
    "imageMasterTrain[\"pixels\"] = imageMasterTrain.height * imageMasterTrain.width\n",
    "# update testing image sizes\n",
    "imageMasterTest[\"pixels\"] = imageMasterTest.height * imageMasterTest.width"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78710713",
   "metadata": {},
   "source": [
    "**Print Image dimensions**\n",
    "\n",
    "This will help to visualize the dimensions of the images in range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553daf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"largest image:\"),display(imageMasterTrain.loc[imageMasterTrain.pixels.argmax()].to_frame().T)\n",
    "print(\"tallest image:\"),display(imageMasterTrain.loc[imageMasterTrain.height.argmax()].to_frame().T)\n",
    "print(\"widest image:\"),display(imageMasterTrain.loc[imageMasterTrain.width.argmax()].to_frame().T)\n",
    "print(\"\\n\")\n",
    "print(\"smallest image:\"),display(imageMasterTrain.loc[imageMasterTrain.pixels.argmin()].to_frame().T)\n",
    "print(\"shortest image:\"),display(imageMasterTrain.loc[imageMasterTrain.height.argmin()].to_frame().T)\n",
    "print(\"leanest image:\"),display(imageMasterTrain.loc[imageMasterTrain.width.argmin()].to_frame().T);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686e8708",
   "metadata": {},
   "source": [
    "**Resizing Images**\n",
    "\n",
    "Resizing images is a critical preprocessing step in computer vision. Machine Learning models  train faster on smaller images and they need images of same size as input.\n",
    "\n",
    "**Some of the Best Practices**\n",
    "\n",
    "1. To decide on what should be the size of the images, a good strategy is to employ \n",
    "progressive  resizing. eg; we can start with all images resized to the smallest one.\n",
    "\n",
    "2. Progressive resizing will train an initial model with very small input images and gauge \n",
    "performance. We can use those weights as the starting point for the next model with larger \n",
    "input images.\n",
    "\n",
    "3. Downsizing larger images to match the size of smaller images is often a better bet \n",
    "than increasing the size of small images to be larger.\n",
    "\n",
    "4. In general, it is safer to maintain the raw image aspect ratio and resize \n",
    "proportionally.\n",
    "\n",
    "5. Make use of image resizing methods like interpolation so that the resized images \n",
    "do not lose much of their perceptual character.\n",
    "\n",
    "\n",
    "**Image Interpolation**\n",
    "\n",
    "Image interpolation occurs when you resize or distort your image from one pixel grid to \n",
    "another. There are two types of interpolation. \n",
    "\n",
    "1. Adaptive : Adaptive methods change depending on what they are interpolating\n",
    "2. Non-adaptive : Non-adaptive methods treat all pixels equally.\n",
    "\n",
    "Higher-Order Interpolation techniques like Spline and Sinc are computationally costly, \n",
    "where as Nearest Neighbor, bilinear are computationally less expensive.\n",
    "\n",
    "**How to best resize the given images?**\n",
    "\n",
    "We can optimally learn representations of images for a given resolution by consistently \n",
    "improving the performance of the common vision models. We can use bilinear interpolation with learnable image resizing module using keras will help to acheive this\n",
    "\n",
    "**Initial Image Size**\n",
    "\n",
    "Based on above review, we shall restrict the image size fed to the network at 50x50 pixels, so as not to detoriate lower resolution images and thus affect model capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c86d1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display 5 random images of 5 random classes\n",
    "classes = np.random.choice(imageMasterTrain.folderName.unique(),5,replace=False)\n",
    "for cls in classes:\n",
    "    dtmp = imageMasterTrain.loc[imageMasterTrain.folderName == cls]\n",
    "    images = np.random.choice(dtmp.ImagePath.values,5,replace=False)\n",
    "    plt.figure(figsize=(20,4))\n",
    "    plt.suptitle(cls)\n",
    "    for i,img in enumerate(images):\n",
    "        img = Image.open(img).resize((200,200))\n",
    "        plt.subplot(1,5,i+1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951728b2",
   "metadata": {},
   "source": [
    "**Step 3**: Map training and testing images to its annotations\n",
    "\n",
    "Read Bounding box and annotations\n",
    "\n",
    "Having connected to the images directories, lets also add the annotations, and add the bounding boxes to the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a746b2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip Annotations.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830668d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us read the annotations datafile to pandas dataframe\n",
    "trainAnnot = pd.read_csv('./Annotations/Train Annotations.csv')\n",
    "testAnnot = pd.read_csv('./Annotations/Test Annotation.csv')\n",
    "Acols = ['Image Name', 'x1', 'y1', 'x2','y2', 'Image class']\n",
    "trainAnnot.columns = Acols\n",
    "testAnnot.columns = Acols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa97cc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#review the content\n",
    "trainAnnot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b8488a",
   "metadata": {},
   "source": [
    "Merge all information of images, annotations, bounding box to single DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6ee387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create all-consolidated dataframes\n",
    "trainDF = pd.merge(imageMasterTrain,trainAnnot,how='outer',left_on='Image',right_on='Image Name')\n",
    "testDF = pd.merge(imageMasterTest,testAnnot,how='outer',left_on='Image',right_on='Image Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5319b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display samples\n",
    "display(trainDF.head(),testDF.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c508183",
   "metadata": {},
   "source": [
    "Merge OEM,MODEL,Type,Year with the above dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8cd877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets merge the OEM, MODEL, TYPE & YEAR data\n",
    "trainDF = pd.merge(trainDF,carsMaster,how='outer',left_on='folderName',right_on='fullNames')\n",
    "testDF = pd.merge(testDF,carsMaster,how='outer',left_on='folderName',right_on='fullNames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb80bc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update class index to start from ZERO\n",
    "trainDF[\"Image class\"] = trainDF[\"Image class\"]-1\n",
    "testDF[\"Image class\"] = testDF[\"Image class\"]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419b8590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge cars_names_and_make csv data with the annotation class name field\n",
    "trainDF = pd.merge(trainDF,carsMaster,how='outer',left_on='Image class',right_index=True)\n",
    "testDF = pd.merge(testDF,carsMaster,how='outer',left_on='Image class',right_index=True)\n",
    "# though this will duplicate the already exisiting folderName, fullNames columns, this adds a cross check for data correctness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643b89eb",
   "metadata": {},
   "source": [
    "**Validate data for any mismatch during merging**\n",
    "\n",
    "After doing the cross merged and synced with \"Train/Test Annotations.csv\", \"Car names and make.csv\" and the images in the \"Train/Test images folders\", it is found to have no mismatch of information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e917a6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# review if any mismatches available\n",
    "display(trainDF.loc[trainDF.folderName!=trainDF.fullNames_x])\n",
    "display(trainDF.loc[trainDF.folderName!=trainDF.fullNames_y])\n",
    "display(trainDF.loc[trainDF.fullNames_x!=trainDF.fullNames_y])\n",
    "display(testDF.loc[testDF.folderName!=testDF.fullNames_x])\n",
    "display(testDF.loc[testDF.folderName!=testDF.fullNames_y])\n",
    "display(testDF.loc[testDF.fullNames_x!=testDF.fullNames_y])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cf148a",
   "metadata": {},
   "source": [
    "**Cleanup - Unwanted columns**\n",
    "\n",
    "Remove unwanted columns and make the dataframe more readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ba36c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalize the images dataframe\n",
    "trainDF = trainDF[[\"ImagePath\",'x1','y1','x2','y2',\"height\",\"width\",\"folderName\",\"OEM_x\",\"MODEL_x\",\"TYPE_x\",\"YEAR_x\",]]\n",
    "testDF = testDF[[\"ImagePath\",'x1','y1','x2','y2',\"height\",\"width\",\"folderName\",\"OEM_x\",\"MODEL_x\",\"TYPE_x\",\"YEAR_x\",]]\n",
    "\n",
    "trainDF.columns = [\"ImagePath\",'x1','y1','x2','y2',\"height\",\"width\",\"className\",\"OEM\",\"MODEL\",\"TYPE\",\"YEAR\"]\n",
    "testDF.columns = [\"ImagePath\",'x1','y1','x2','y2',\"height\",\"width\",\"className\",\"OEM\",\"MODEL\",\"TYPE\",\"YEAR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5957075d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221e651e",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a35aed4",
   "metadata": {},
   "source": [
    "**Check for null values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e240c1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# review for any missing values\n",
    "trainDF.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8f55c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d0fa62",
   "metadata": {},
   "source": [
    "**Step 4**: Display images with bounding box\n",
    "\n",
    "Visualization - Images with bounding box and annotations - 5 Nos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09d67a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display 5 random images of 5 random classes with respective bounding boxes from the annotations csv\n",
    "classes = np.random.choice(trainDF.className.unique(),5,replace=False)\n",
    "tfi = tf.keras.preprocessing.image\n",
    "for cls in classes:\n",
    "    dtmp = trainDF.loc[trainDF.className == cls]\n",
    "    ind = np.random.choice(dtmp.index,5,replace=False)\n",
    "    images = dtmp.loc[ind][\"ImagePath\"]\n",
    "    x1 = dtmp.loc[ind][\"x1\"].values\n",
    "    y1 = dtmp.loc[ind][\"y1\"].values\n",
    "    x2 = dtmp.loc[ind][\"x2\"].values\n",
    "    y2 = dtmp.loc[ind][\"y2\"].values\n",
    "\n",
    "    plt.figure(figsize=(20,4))\n",
    "    plt.suptitle(cls)\n",
    "    for i,img in enumerate(images):\n",
    "        img = tfi.img_to_array(tfi.load_img(img))\n",
    "        cv2.rectangle(img,(x1[i],y1[i]),(x2[i],y2[i]),(0,255,0),2)\n",
    "        img = tfi.array_to_img(tf.image.resize(img,(200,200)))\n",
    "        plt.subplot(1,5,i+1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92eb4421",
   "metadata": {},
   "source": [
    "**Visualize**\n",
    "\n",
    "**Number of Images per OEM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460e11eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of images from each OEM\n",
    "plt.figure(figsize = (25,5))\n",
    "ax = sns.barplot(x=trainDF[\"OEM\"].value_counts().index,y=trainDF[\"OEM\"].value_counts().values) # display bars\n",
    "ax.bar_label(ax.containers[0]) # display counts\n",
    "plt.title(\"Number of images from each OEM\",x=0.5,y=0.9)\n",
    "plt.ylabel(\"number of images\")\n",
    "plt.xticks(rotation=60);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320a11fd",
   "metadata": {},
   "source": [
    "**Distribution** : Total number of OEM - Chevrolet - 905\n",
    "\n",
    "The Chevrolet is having 60% of contribution for the images in train dataset\n",
    "\n",
    "The Maybach is having the least contribution of images in train dataset, as 0.03%\n",
    "\n",
    "This help to understand about the imbalance of data for OEM-images dataset\n",
    "\n",
    "**Visualize**\n",
    "\n",
    "**Number of Images per OEM-Type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c97a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of images from each TYPE\n",
    "plt.figure(figsize = (25,5))\n",
    "ax = sns.barplot(x=trainDF[\"TYPE\"].value_counts().index,y=trainDF[\"TYPE\"].value_counts().values) # display bars\n",
    "ax.bar_label(ax.containers[0]) # display counts\n",
    "plt.title(\"Number of images from each TYPE\",x=0.5,y=0.9)\n",
    "plt.ylabel(\"number of images\")\n",
    "plt.xticks(rotation=60);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc28d042",
   "metadata": {},
   "source": [
    "**Distribution** : Total number of Mitsubishi-Sedan - 1907\n",
    "\n",
    "The Mitsubishi-Sedan is having 26% of contribution for the images in train dataset\n",
    "\n",
    "The Express Van is having the least contribution of images in train dataset, as 0.04%\n",
    "\n",
    "This help to understand about the imbalance of data for Model-images dataset\n",
    "\n",
    "**Visualize**\n",
    "\n",
    "**Number of Images per Year**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0e1b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of images from each YEAR\n",
    "plt.figure(figsize = (25,5))\n",
    "ax = sns.barplot(x=trainDF[\"YEAR\"].value_counts().index,y=trainDF[\"YEAR\"].value_counts().values) # display bars\n",
    "ax.bar_label(ax.containers[0]) # display counts\n",
    "plt.title(\"Number of images from each TYPE\",x=0.5,y=0.9)\n",
    "plt.ylabel(\"number of images\")\n",
    "plt.xticks(rotation=60);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9250a44a",
   "metadata": {},
   "source": [
    "**Distribution** : Total number of images for year 2012 - 4818\n",
    "\n",
    "The 2012 is having 60% of contribution for the images in train dataset\n",
    "\n",
    "The 1997-1999 is having the least contribution of images in train dataset, as 0.05%\n",
    "\n",
    "This help to understand about the imbalance of data for Year-images dataset\n",
    "\n",
    "**Distribution of Support**\n",
    "\n",
    "The box plot shows how the distribution of images are there for each class / category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b218c0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of support for each class\n",
    "plt.figure(figsize = (25,5))\n",
    "sns.boxplot(x=trainDF[\"className\"].value_counts())\n",
    "plt.xlabel(\"support for each class\")\n",
    "plt.title(\"distribution of support for each class\",x=0.1,y=0.9);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eba90e",
   "metadata": {},
   "source": [
    "**Print Cross distribution of the Type from each OEM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a519839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us study the cross distribution of the TYPE of car from each OEM\n",
    "pivot = trainDF.groupby(by=[\"OEM\",\"TYPE\",\"YEAR\"])[\"className\"].count().to_frame()\n",
    "pivot.reset_index(inplace=True)\n",
    "pivot.columns=[\"OEM\",\"TYPE\",\"YEAR\",\"COUNTS\"]\n",
    "pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2641ee93",
   "metadata": {},
   "source": [
    "**Print distribution of support images**\n",
    "\n",
    "The combinations are only within 40~50 images each, whith few extreme counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d089216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of support for each class\n",
    "plt.figure(figsize = (25,5))\n",
    "sns.boxplot(x=pivot.COUNTS)\n",
    "plt.xlabel(\"Count of images per combinations\")\n",
    "plt.title(\"distribution of image counts over combinations\",x=0.5,y=0.9);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b5f296",
   "metadata": {},
   "source": [
    "**Print Combination with more than 50 image (Average)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70498d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combinations with more than 50 images each\n",
    "graphDF = pivot.loc[pivot.COUNTS>50]\n",
    "plt.figure(figsize=(15,7))\n",
    "ax = sns.scatterplot(x=graphDF.OEM,y=graphDF.TYPE,hue=graphDF.YEAR,size=graphDF.COUNTS,sizes=(75,300))\n",
    "plt.xticks(rotation=60)\n",
    "plt.legend(loc='lower left')\n",
    "\n",
    "for i in range(len(graphDF)):\n",
    "    xpos = (np.argwhere(graphDF.OEM.unique()==graphDF.OEM.values[i])[0][0])# / graphDF.OEM.nunique()\n",
    "    ypos = (np.argwhere(graphDF.TYPE.unique()==graphDF.TYPE.values[i])[0][0])# / graphDF.TYPE.nunique()\n",
    "    ax.annotate(text=str(graphDF.COUNTS.values[i]), xy=(xpos,ypos), xycoords='data', \n",
    "                xytext=(8,1), textcoords='offset points')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9d7a5d",
   "metadata": {},
   "source": [
    "**Print Combination with less than 35 image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e0747f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combinations with less than 35 images each\n",
    "graphDF = pivot.loc[pivot.COUNTS<35]\n",
    "plt.figure(figsize=(15,7))\n",
    "ax = sns.scatterplot(x=graphDF.OEM,y=graphDF.TYPE,hue=graphDF.YEAR,size=graphDF.COUNTS,sizes=(75,300))\n",
    "plt.xticks(rotation=60)\n",
    "plt.legend(loc='lower left')\n",
    "\n",
    "for i in range(len(graphDF)):\n",
    "    xpos = (np.argwhere(graphDF.OEM.unique()==graphDF.OEM.values[i])[0][0])# / graphDF.OEM.nunique()\n",
    "    ypos = (np.argwhere(graphDF.TYPE.unique()==graphDF.TYPE.values[i])[0][0])# / graphDF.TYPE.nunique()\n",
    "    ax.annotate(text=str(graphDF.COUNTS.values[i]), xy=(xpos,ypos), xycoords='data', \n",
    "                xytext=(8,1), textcoords='offset points')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f183363",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "1. All the data preprocessing & compilation have been completed so far\n",
    "2. The data were imported and mapped against their respective classses & annotations\n",
    "3. Comprehensive dataframes for training & testing datasets were created and could be used with generators for Deep Learning Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9115089",
   "metadata": {},
   "source": [
    "**Step 5**: Design, train and test basic CNN models to classify the car."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afebd8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b7659b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d20298d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d52e74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and validation data\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
    "                                                                 shear_range=0.2,\n",
    "                                                                 zoom_range=0.2,\n",
    "                                                                 horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44dec686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8144 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        \"C:/Users/HP/AIML/Capstone project/cars_train\",\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b496704b",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94eeb880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8048 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        \"C:/Users/HP/AIML/Capstone project/cars_test\",\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11accb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_9620/3452444645.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "62/62 [==============================] - 66s 1s/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/50\n",
      "62/62 [==============================] - 63s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "62/62 [==============================] - 60s 962ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "62/62 [==============================] - 58s 932ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "62/62 [==============================] - 68s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "62/62 [==============================] - 56s 907ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "62/62 [==============================] - 57s 920ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "62/62 [==============================] - 56s 898ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "62/62 [==============================] - 57s 926ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "62/62 [==============================] - 56s 912ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "62/62 [==============================] - 54s 872ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "62/62 [==============================] - 54s 878ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "62/62 [==============================] - 59s 958ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "62/62 [==============================] - 60s 974ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "62/62 [==============================] - 57s 918ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "62/62 [==============================] - 57s 927ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "62/62 [==============================] - 59s 956ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "62/62 [==============================] - 57s 912ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "62/62 [==============================] - 56s 903ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "62/62 [==============================] - 54s 876ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "62/62 [==============================] - 57s 919ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "62/62 [==============================] - 54s 879ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "62/62 [==============================] - 53s 848ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "62/62 [==============================] - 54s 870ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "62/62 [==============================] - 53s 855ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "62/62 [==============================] - 53s 854ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "62/62 [==============================] - 54s 879ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "62/62 [==============================] - 56s 904ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "62/62 [==============================] - 55s 893ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "62/62 [==============================] - 56s 910ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "62/62 [==============================] - 56s 910ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "62/62 [==============================] - 57s 916ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "62/62 [==============================] - 57s 920ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "62/62 [==============================] - 83s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "62/62 [==============================] - 72s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "62/62 [==============================] - 87s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "62/62 [==============================] - 89s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "62/62 [==============================] - 90s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "62/62 [==============================] - 85s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "62/62 [==============================] - 85s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "62/62 [==============================] - 87s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "62/62 [==============================] - 85s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "62/62 [==============================] - 68s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "62/62 [==============================] - 84s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "62/62 [==============================] - 82s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "62/62 [==============================] - 65s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "62/62 [==============================] - 76s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "62/62 [==============================] - 86s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "62/62 [==============================] - 84s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "62/62 [==============================] - 88s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16be1b83a30>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // 32,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800 // 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2b47667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8048 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        \"C:/Users/HP/AIML/Capstone project/cars_test\",\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fb0fa04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_9620/1490490613.py:1: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  test_loss, test_acc = model.evaluate_generator(test_generator, steps=800 // 32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate_generator(test_generator, steps=800 // 32)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0c1fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67fcce9b",
   "metadata": {},
   "source": [
    "# old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00942a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os, pickle, re, sys\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b4b122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(32, input_shape=(784,)),\n",
    "    Activation('relu'),\n",
    "    Dense(10),\n",
    "    Activation('softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662babdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATION_PATH =  \"C:/Users/HP/AIML/Capstone project/Annotations\"\n",
    "TRAIN_IMAGES_DIR_PATH = \"C:/Users/HP/AIML/Capstone project/cars_train\"\n",
    "TEST_IMAGES_DIR_PATH = \"C:/Users/HP/AIML/Capstone project/cars_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb94fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Flatten, Dropout\n",
    "\n",
    "Image_Size = 224\n",
    "Batch_Size = 32\n",
    "Epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211d1705",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "#model checkpoint to save the model after every epoch\n",
    "SavePath = \"models/ResNetModel_weights.{epoch:02d}.hdf5\"\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath=SavePath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='auto')\n",
    "\n",
    "lr_schedule = LearningRateScheduler(lambda epoch: 1e-8 * 10**(epoch/2)) # change learning rate from 1e-8 to 1e-3\n",
    "\n",
    "Redlr = ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.1, patience=5, verbose=0,\n",
    "    mode='auto', min_delta=0.0001, cooldown=0, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b3759d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(TRAIN_IMAGES_DIR_PATH, target_size = (Image_Size, Image_Size), batch_size=Batch_Size, class_mode='categorical')\n",
    "test_generator = test_datagen.flow_from_directory(TEST_IMAGES_DIR_PATH, target_size = (Image_Size, Image_Size), batch_size=Batch_Size, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c7c16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "\n",
    "base_model = MobileNet(input_shape=(Image_Size, Image_Size, 3), include_top=False)\n",
    "\n",
    "#Freeze all the layers\n",
    "for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x) #average pooling of the last feature extractor layer \n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(196, activation='softmax')(x) #Dense layer for 196 output class\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf21aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d0efdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.listdir(\"C:/Users/HP/AIML/Capstone project/cars_train\"))\n",
    "print(os.listdir(\"C:/Users/HP/AIML/Capstone project/cars_test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c95a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_generator, steps_per_epoch=len(train_generator), epochs=10, validation_data=test_generator, validation_steps=len(test_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0a0ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "#model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f9c6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#history = model.fit(train_generator, steps_per_epoch=len(train_generator), epochs=10, validation_data=test_generator, validation_steps=len(test_generator))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc1b962",
   "metadata": {},
   "source": [
    "# Milestone 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149ea8e7",
   "metadata": {},
   "source": [
    "## step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da2480e",
   "metadata": {},
   "source": [
    "## Fine tune the trained basic CNN models to classify the car."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18b32dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93ebc029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 8s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained VGG16 model (without the top layers)\n",
    "vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f9f8ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the weights of the pre-trained layers\n",
    "for layer in vgg16.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a929b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new trainable layers on top of the pre-trained model\n",
    "model = models.Sequential()\n",
    "model.add(vgg16)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e616b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e27386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and validation data\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
    "                                                                 shear_range=0.2,\n",
    "                                                                 zoom_range=0.2,\n",
    "                                                                 horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90dc46fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8144 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        \"C:/Users/HP/AIML/Capstone project/cars_train\",\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc92e8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8144 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        \"C:/Users/HP/AIML/Capstone project/cars_train\",\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55e72274",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_9620/118867465.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "13/62 [=====>........................] - ETA: 1:30 - loss: 0.0935 - accuracy: 0.9231"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9620/118867465.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Fine-tune the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m history = model.fit_generator(\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2000\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2602\u001b[0m             \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2603\u001b[0m         )\n\u001b[1;32m-> 2604\u001b[1;33m         return self.fit(\n\u001b[0m\u001b[0;32m   2605\u001b[0m             \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2606\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1648\u001b[0m                         ):\n\u001b[0;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1650\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1651\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    910\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 912\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    913\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    132\u001b[0m       (concrete_function,\n\u001b[0;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[1;33m     return concrete_function._call_flat(\n\u001b[0m\u001b[0;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1745\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Fine-tune the model\n",
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // 32,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800 // 32,\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "553b7b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8048 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_9620/1609818895.py:9: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  test_loss, test_acc = model.evaluate_generator(test_generator, steps=800 // 32)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9620/1609818895.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m         class_mode='binary')\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m800\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test accuracy:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[1;34m(self, generator, steps, callbacks, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[0;32m   2644\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_call_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"evaluate_generator\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m         return self.evaluate(\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2648\u001b[0m             \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   2038\u001b[0m                         ):\n\u001b[0;32m   2039\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2040\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2041\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2042\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    918\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 919\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    920\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    921\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    132\u001b[0m       (concrete_function,\n\u001b[0;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[1;33m     return concrete_function._call_flat(\n\u001b[0m\u001b[0;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1745\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        \"C:/Users/HP/AIML/Capstone project/cars_test\",\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f313221a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate_generator(test_generator, steps=800 // 32)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba81fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
